{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]], columns=[\"A\", \"B\", \"C\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape #num of rows and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() #memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.size #total number of items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading dataframes from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load csv file\n",
    "\n",
    "coffee = pd.read_csv('./warmup-data/coffee.csv')\n",
    "\n",
    "bios = pd.read_csv('./data/bios.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load parquet file\n",
    "\n",
    "results = pd.read_parquet('./data/results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load excel file\n",
    "\n",
    "# olympics_data = pd.read_excel('./data/olympics-data.xlsx')\n",
    "\n",
    "#including sheet_name\n",
    "olympics_data = pd.read_excel('./data/olympics-data.xlsx', sheet_name=\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assessing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coffee\n",
    "# print(coffee)\n",
    "# display(coffee)\n",
    "coffee.sample(10) #random values\n",
    "# coffee.sample(10, random_state=1) #deterministic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alter index\n",
    "# coffee.index = coffee[\"Day\"]\n",
    "# coffee.loc[\"Monday\":\"Wednesday\", \"Units Sold\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Access specific rows and columns\n",
    "\n",
    "#loc\n",
    "# coffee.loc[[0,1,2]]\n",
    "\n",
    "#Slice\n",
    "# coffee.loc[5:12]\n",
    "\n",
    "#Slice by column name\n",
    "# coffee.loc[5:12, \"Day\"]\n",
    "# coffee.loc[5:12, [\"Day\", \"Units Sold\"]]\n",
    "\n",
    "#iloc #only using index values\n",
    "coffee.iloc[5:12, [0,2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update a record using loc #Latte Units Sold\n",
    "coffee.loc[1, \"Units Sold\"] = 10\n",
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.at[0,\"Units Sold\"] #only single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.iat[0,0] #only single values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee[\"Day\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffee.sort_values(\"Units Sold\", ascending=False) #defaults as ASC order\n",
    "coffee.sort_values([\"Units Sold\", \"Coffee Type\"], ascending=[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in coffee.iterrows():\n",
    "    print(index)\n",
    "    print(row)\n",
    "    print(\"\\n\\n\")\n",
    "    \n",
    "#does have a neg performance impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets look at height and weight\n",
    "bios.info()\n",
    "\n",
    "#height and weight are floats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.loc[bios[\"height_cm\"] > 215, ['name', 'height_cm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[(bios[\"height_cm\"] > 215) & (bios['born_country']=='AUS')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios[bios['name'].str.contains(\"Luc\")] #case sensitive\n",
    "bios[bios['name'].str.contains(\"luc|patrick\", case=False)] #regex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Find all athletes born in cities that start with a vowel\n",
    "vowel_cities = bios[bios['born_city'].str.contains(r'^[AEIOUaeiou]', na=False)]\n",
    "vowel_cities.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find athletes names ending in 'son'\n",
    "son_names = bios[bios['name'].str.contains(r'son$', case=False, na=False)]\n",
    "son_names.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find athletes with names that do not contain a vowel\n",
    "no_vowels = bios[bios['name'].str.contains(r'^[AEIOUaeiou]*$', na=False)]\n",
    "no_vowels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find athletes whose names contain a hyphen or an apostrophe\n",
    "hyphen_apostrophe = bios[bios['name'].str.contains(r\"[-']\", na=False)]\n",
    "hyphen_apostrophe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isin\n",
    "# bios[bios[\"born_country\"].isin([\"FRA\", \"ABC\", \"AUS\"])] #Added non country to see what the impact would be\n",
    "bios[bios[\"born_country\"].isin([\"FRA\", \"ABC\", \"AUS\"]) & (bios['name'].str.startswith(\"Bob\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way of filtering results\n",
    "bios.query('born_country == \"AUS\" and born_city == \"Sydney\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding and removing columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# coffee.head(2)\n",
    "coffee[\"Price\"] = 5.99 #all coffee types will have 5.99 as price\n",
    "coffee.head(2)\n",
    "\n",
    "coffee[\"Price\"] = np.where(coffee[\"Coffee Type\"]==\"Espresso\", 4.25, 5.99)\n",
    "coffee.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop column\n",
    "# coffee.drop(columns=['Price'], inplace=True)\n",
    "coffee.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = coffee.rename(columns={'New_Price': 'Price'}) # or can use inplace=True without resetting (coffee=)\n",
    "coffee.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['Revenue'] = coffee['Units Sold'] * coffee['Price']\n",
    "coffee.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a copy of the source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new = bios.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new['first_name'] = bios_new['name'].str.split(' ').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new.head(2)\n",
    "bios_new.query('first_name == \"Keith\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert born_date to date data type -> heaps of format methods for date data type look up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bios_new.info()\n",
    "bios_new['born_datetime'] = pd.to_datetime(bios_new['born_date'])\n",
    "bios_new.head(2)\n",
    "bios_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create \"year\" column from \"born_datetime\" column, now  \"born_datetime\" has been created as datetime data type\n",
    "bios_new['born_year'] = bios_new['born_datetime'].dt.year\n",
    "\n",
    "bios_new[['name', 'born_year']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save new file to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new.to_csv('./data/bios_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create custom columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['height_category'] = bios['height_cm'].apply(lambda x: 'short' if x <165 else ('average' if x < 185 else 'tall'))\n",
    "bios.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function to populate a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_athlete(row):\n",
    "    if row['height_cm'] <175 and row['weight_kg'] <70:\n",
    "        return 'Lightweight'\n",
    "    elif row['height_cm'] <180 and row['weight_kg'] <80:\n",
    "        return 'Middleweight'\n",
    "    \n",
    "    else:\n",
    "        return 'Heavyweight'\n",
    "    \n",
    "bios['Category'] = bios.apply(categorize_athlete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge and concatenating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nocs = pd.read_csv('./data/noc_regions.csv')\n",
    "nocs.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = pd.merge(bios, nocs, left_on='born_country', right_on='NOC', how='left', suffixes=[\"bios\", \"nocdf\"]) #how= same concept as sql joins\n",
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.rename(columns={'region': 'born_country_full'}, inplace=True)\n",
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios = bios.drop(['NOC_x','NOC_y'],axis=1)\n",
    "bios.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['NOCbios'] != bios['born_country_full']\n",
    "bios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create new dfs and then concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus = bios[bios['born_country']=='AUS'].copy()\n",
    "gbr = bios[bios['born_country']=='GBR'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aus_gbr = pd.concat([aus,gbr])\n",
    "aus_gbr.tail(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(results, bios, on='athlete_id', how='left')\n",
    "combined_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For the purpose of study, adding null values into dataframe\n",
    "coffee.loc[[0,1], 'Units Sold'] = np.nan\n",
    "coffee.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for null|na in dataframe\n",
    "coffee.info()\n",
    "coffee.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = coffee.fillna(coffee['Units Sold'].mean())\n",
    "#coffee = coffee.fillna(coffee['Units Sold'].interpolate()) #applies values based on the pattern of the values in the dataframe.\n",
    "\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop entire row where there is a null|na\n",
    "coffee.dropna()\n",
    "\n",
    "#coffee.dropna(subset=['Units Sold'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find rows where null|na found in a column\n",
    "coffee[coffee['Units Sold'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find rows where there is no null|na found in a column\n",
    "coffee[coffee['Units Sold'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aggregating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['born_city'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[bios['born_country']=='AUS']['born_region'].value_counts() #.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['born_date'] = pd.to_datetime(bios['born_date'])\n",
    "\n",
    "#Most common birth year\n",
    "bios.groupby(bios['born_date'].dt.year)['name'].count().reset_index().sort_values('name', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.groupby(['Coffee Type'])['Units Sold'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.groupby(['Coffee Type']).agg({'Units Sold': 'sum', 'Price': 'mean'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.groupby(['Coffee Type', 'Day']).agg({'Units Sold': 'sum', 'Price': 'mean'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = coffee.pivot(columns='Coffee Type', index='Day', values='Revenue')\n",
    "pivot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.loc['Monday','Latte']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advanced Funtionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shift -> comparring data .... similar to lead | lag???\n",
    "coffee['yesterday_revenue'] = coffee['Revenue'].shift(2) # can use .shift(-2) as well\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['pct_change'] = coffee['Revenue'] / coffee['yesterday_revenue']\n",
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare weights\n",
    "bios['height_rank'] = bios['height_cm'].rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.sort_values(['height_rank'],ascending=False)\n",
    "bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.sort_values(['height_rank']).sample(10)[['name', 'height_rank']]\n",
    "bios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumlative revenue\n",
    "coffee['cumlative_revenue'] = coffee['Revenue'].cumsum()\n",
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cumlative revenue last 3 days for latte\n",
    "latte = coffee[coffee['Coffee Type']==\"Latte\"].copy()\n",
    "latte['3day'] = latte['Units Sold'].rolling(3).sum()\n",
    "latte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "New funtionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_numpy = pd.read_csv('./data/results.csv')\n",
    "results_arrow = pd.read_csv('./data/results.csv', engine='pyarrow', dtype_backend='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 308408 entries, 0 to 308407\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   year        305807 non-null  float64\n",
      " 1   type        305807 non-null  object \n",
      " 2   discipline  308407 non-null  object \n",
      " 3   event       308408 non-null  object \n",
      " 4   as          308408 non-null  object \n",
      " 5   athlete_id  308408 non-null  int64  \n",
      " 6   noc         308407 non-null  object \n",
      " 7   team        121714 non-null  object \n",
      " 8   place       283193 non-null  float64\n",
      " 9   tied        308408 non-null  bool   \n",
      " 10  medal       44139 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(1), object(7)\n",
      "memory usage: 23.8+ MB\n"
     ]
    }
   ],
   "source": [
    "results_numpy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 308408 entries, 0 to 308407\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count   Dtype          \n",
      "---  ------      --------------   -----          \n",
      " 0   year        305807 non-null  double[pyarrow]\n",
      " 1   type        305807 non-null  string[pyarrow]\n",
      " 2   discipline  308407 non-null  string[pyarrow]\n",
      " 3   event       308408 non-null  string[pyarrow]\n",
      " 4   as          308408 non-null  string[pyarrow]\n",
      " 5   athlete_id  308408 non-null  int64[pyarrow] \n",
      " 6   noc         308407 non-null  string[pyarrow]\n",
      " 7   team        121714 non-null  string[pyarrow]\n",
      " 8   place       283193 non-null  double[pyarrow]\n",
      " 9   tied        308408 non-null  bool[pyarrow]  \n",
      " 10  medal       44139 non-null   string[pyarrow]\n",
      "dtypes: bool[pyarrow](1), double[pyarrow](2), int64[pyarrow](1), string[pyarrow](7)\n",
      "memory usage: 37.5 MB\n"
     ]
    }
   ],
   "source": [
    "results_arrow.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
